{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96a1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category_encoders) (1.22.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category_encoders) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category_encoders) (1.11.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category_encoders) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72162914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import inflection\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "from category_encoders       import OneHotEncoder\n",
    "from xgboost                 import XGBClassifier\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics         import balanced_accuracy_score, precision_score, classification_report\n",
    "from sklearn.metrics         import recall_score, f1_score, make_scorer, cohen_kappa_score\n",
    "from sagemaker.debugger      import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.session       import TrainingInput\n",
    "from sagemaker.serializers   import CSVSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1923eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_scores(model_name, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate and return various classification metrics for a machine learning model's performance.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Name or identifier for the machine learning model.\n",
    "    - y_true (array-like): True labels for the data.\n",
    "    - y_pred (array-like): Predicted labels for the data.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the following metrics:\n",
    "        - 'Balanced Accuracy': Balanced accuracy score rounded to 3 decimal places.\n",
    "        - 'Precision': Precision score rounded to 3 decimal places.\n",
    "        - 'Recall': Recall score rounded to 3 decimal places.\n",
    "        - 'F1': F1 score rounded to 3 decimal places.\n",
    "        - 'Kappa': Cohen's kappa score rounded to 3 decimal places.\n",
    "    \n",
    "    This function calculates and reports commonly used classification metrics such as balanced accuracy, precision, recall, F1 score,\n",
    "    and Cohen's kappa score for evaluating the performance of a classification model. The results are returned as a DataFrame with the\n",
    "    model's name as the index.\n",
    "\n",
    "    Example usage:\n",
    "    >>> y_true = [0, 1, 1, 0, 1]\n",
    "    >>> y_pred = [0, 1, 0, 0, 1]\n",
    "    >>> model_name = 'MyClassifier'\n",
    "    >>> metrics_df = ml_scores(model_name, y_true, y_pred)\n",
    "    >>> print(metrics_df)\n",
    "               Balanced Accuracy  Precision  Recall     F1  Kappa\n",
    "    MyClassifier             0.75        1.0     0.5  0.667   0.4\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    return pd.DataFrame({'Balanced Accuracy': np.round(accuracy, 3), \n",
    "                         'Precision': np.round(precision, 3), \n",
    "                         'Recall': np.round(recall, 3),\n",
    "                         'F1': np.round(f1, 3),\n",
    "                         'Kappa': np.round(kappa, 3)}, \n",
    "                        index=[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55474d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_cv_results(model_name, model, x, y, verbose=1):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return the mean and standard deviation of various classification metrics for a machine learning model.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Name or identifier for the machine learning model.\n",
    "    - model (object): The machine learning model to be evaluated.\n",
    "    - x (pd.DataFrame): Input features for the data.\n",
    "    - y (pd.Series): True labels for the data.\n",
    "    - verbose (int, optional): Verbosity level. If 1, it will print fold information. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the mean and standard deviation of the following metrics across folds:\n",
    "        - 'Balanced Accuracy': Mean and standard deviation as \"{mean} +/- {std}\".\n",
    "        - 'Precision': Mean and standard deviation as \"{mean} +/- {std}\".\n",
    "        - 'Recall': Mean and standard deviation as \"{mean} +/- {std}\".\n",
    "        - 'F1': Mean and standard deviation as \"{mean} +/- {std}\".\n",
    "        - 'Kappa': Mean and standard deviation as \"{mean} +/- {std}\".\n",
    "    \n",
    "    This function performs cross-validation to evaluate the performance of a classification model. It calculates and reports the mean and\n",
    "    standard deviation of metrics such as balanced accuracy, precision, recall, F1 score, and Cohen's kappa score across different folds.\n",
    "\n",
    "    Example usage:\n",
    "    >>> from sklearn.linear_model import LogisticRegression\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> data = load_iris()\n",
    "    >>> x = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    >>> y = pd.Series(data.target)\n",
    "    >>> model = LogisticRegression()\n",
    "    >>> model_name = 'LogisticRegression'\n",
    "    >>> cv_results = ml_cv_results(model_name, model, x, y)\n",
    "    >>> print(cv_results)\n",
    "                       Balanced Accuracy         Precision            Recall                 F1              Kappa\n",
    "    LogisticRegression  0.966 +/- 0.032  0.967 +/- 0.053  0.967 +/- 0.053  0.966 +/- 0.053  0.951 +/- 0.072\n",
    "    \"\"\"\n",
    "    \n",
    "    '''initial'''\n",
    "    balanced_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    kappas = []\n",
    "    \n",
    "    mm = MinMaxScaler()\n",
    "    \n",
    "    x_ = x.to_numpy()\n",
    "    y_ = y.to_numpy()\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    '''cross-validation'''\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    for index_train, index_test in skf.split(x_, y_):\n",
    "        ## Showing the Fold\n",
    "        if verbose > 0:\n",
    "            count += 1\n",
    "            print('Fold K=%i' % (count))\n",
    "    \n",
    "        ## selecting train and test\n",
    "        x_train, x_test = x.iloc[index_train], x.iloc[index_test]\n",
    "        y_train, y_test = y.iloc[index_train], y.iloc[index_test]\n",
    "        \n",
    "        ## applying the scale\n",
    "        x_train = mm.fit_transform(x_train)\n",
    "        x_test = mm.transform(x_test)\n",
    "    \n",
    "        ## training the model\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        ## saving the metrics\n",
    "        balanced_accuracies.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "        kappas.append(cohen_kappa_score(y_test, y_pred))\n",
    "        \n",
    "        \n",
    "    '''results'''    \n",
    "    accuracy_mean, accuracy_std = np.round(np.mean(balanced_accuracies), 3), np.round(np.std(balanced_accuracies), 3)\n",
    "    precision_mean, precision_std = np.round(np.mean(precisions), 3), np.round(np.std(precisions), 3)\n",
    "    recall_mean, recall_std = np.round(np.mean(recalls), 3), np.round(np.std(recalls), 3)\n",
    "    f1_mean, f1_std = np.round(np.mean(f1s), 3), np.round(np.std(f1s), 3)\n",
    "    kappa_mean, kappa_std = np.round(np.mean(kappas), 3), np.round(np.std(kappas), 3)\n",
    "    \n",
    "    ## saving the results in a dataframe\n",
    "    return pd.DataFrame({\"Balanced Accuracy\": \"{} +/- {}\".format(accuracy_mean, accuracy_std),\n",
    "                        \"Precision\": \"{} +/- {}\".format(precision_mean, precision_std),\n",
    "                        \"Recall\": \"{} +/- {}\".format(recall_mean, recall_std),\n",
    "                        \"F1\": \"{} +/- {}\".format(f1_mean, f1_std),\n",
    "                        \"Kappa\": \"{} +/- {}\".format(kappa_mean, kappa_std)},\n",
    "                       index=[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d93511",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f65dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from S3\n",
    "'''\n",
    "step: represents a unit of time where 1 step equals 1 hour\n",
    "type: type of online transaction\n",
    "amount: the amount of the transaction\n",
    "nameOrig: customer starting the transaction\n",
    "oldbalanceOrg: balance before the transaction\n",
    "newbalanceOrig: balance after the transaction\n",
    "nameDest: recipient of the transaction\n",
    "oldbalanceDest: initial balance of recipient before the transaction\n",
    "newbalanceDest: the new balance of recipient after the transaction\n",
    "isFraud: fraud transaction\n",
    "'''\n",
    "s3_data_location = 's3://archana-training-data/onlinefraud.csv'\n",
    "data = pd.read_csv(s3_data_location)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004813c",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4dab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns Rename\n",
    "cols_old = data.columns.tolist()\n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "\n",
    "data.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b52800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Data Type\n",
    "data['is_fraud'] = data['is_fraud'].map({1: 'yes', 0: 'no'})\n",
    "data['is_flagged_fraud'] = data['is_flagged_fraud'].map({1: 'yes', 0: 'no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b031587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "newData = data.copy()\n",
    "\n",
    "# step\n",
    "newData['step_days'] = newData['step'].apply(lambda i: i/24)\n",
    "newData['step_weeks'] = newData['step'].apply(lambda i: i/(24*7))\n",
    "\n",
    "# difference between initial balance before the transaction and new balance after the transaction\n",
    "newData['diff_new_old_balance'] = newData['newbalance_orig'] - newData['oldbalance_org']\n",
    "\n",
    "# difference between initial balance recipient before the transaction and new balance recipient after the transaction.\n",
    "newData['diff_new_old_destiny'] = newData['newbalance_dest'] - newData['oldbalance_dest']\n",
    "\n",
    "# name orig and name dest\n",
    "newData['name_orig'] = newData['name_orig'].apply(lambda i: i[0])\n",
    "newData['name_dest'] = newData['name_dest'].apply(lambda i: i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af3fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into Train, Valid and Test\n",
    "X = newData.drop(columns=['is_fraud', 'is_flagged_fraud', 'name_orig', 'name_dest', \n",
    "                      'step_weeks', 'step_days'], axis=1)\n",
    "y = newData['is_fraud'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "# spliting into temp and test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=.2, stratify=y)\n",
    "\n",
    "# spliting into train and valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=.2, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d9a0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoder\n",
    "ohe = OneHotEncoder(cols=['type'], use_cat_names=True)\n",
    "\n",
    "X_train = ohe.fit_transform(X_train)\n",
    "X_valid = ohe.transform(X_valid)\n",
    "\n",
    "X_temp = ohe.fit_transform(X_temp)\n",
    "X_test = ohe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8b86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling\n",
    "num_columns = ['amount', 'oldbalance_org', 'newbalance_orig', 'oldbalance_dest', 'newbalance_dest',\n",
    "               'diff_new_old_balance', 'diff_new_old_destiny']\n",
    "mm = MinMaxScaler()\n",
    "X_params = X_temp.copy()\n",
    "\n",
    "X_train[num_columns] = mm.fit_transform(X_train[num_columns])\n",
    "X_valid[num_columns] = mm.transform(X_valid[num_columns])\n",
    "\n",
    "X_params[num_columns] = mm.fit_transform(X_temp[num_columns])\n",
    "X_test[num_columns] = mm.transform(X_test[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94987481",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns_selected = ['step', 'oldbalance_org', \n",
    "                          'newbalance_orig', 'newbalance_dest', \n",
    "                          'diff_new_old_balance', 'diff_new_old_destiny', \n",
    "                          'type_TRANSFER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b969f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cs = X_train[final_columns_selected]\n",
    "X_valid_cs = X_valid[final_columns_selected]\n",
    "\n",
    "X_temp_cs = X_temp[final_columns_selected]\n",
    "X_test_cs = X_test[final_columns_selected]\n",
    "\n",
    "X_params_cs = X_params[final_columns_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27623d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         step  oldbalance_org  newbalance_orig  newbalance_dest  \\\n",
      "1035243    94        0.047279         0.058727         0.000784   \n",
      "1977046   178        0.001274         0.000000         0.011089   \n",
      "3507208   259        0.000436         0.000362         0.000000   \n",
      "496331     20        0.000000         0.000000         0.002438   \n",
      "5110653   355        0.000000         0.000000         0.000000   \n",
      "\n",
      "         diff_new_old_balance  diff_new_old_destiny  type_TRANSFER  \n",
      "1035243              0.856759              0.109188              0  \n",
      "1977046              0.842264              0.110734              0  \n",
      "3507208              0.848023              0.109987              0  \n",
      "496331               0.848708              0.111695              1  \n",
      "5110653              0.848708              0.109987              0  \n",
      "1035243    0\n",
      "1977046    0\n",
      "3507208    0\n",
      "496331     0\n",
      "5110653    0\n",
      "Name: is_fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cs.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88e512",
   "metadata": {},
   "source": [
    "## XGB Classifier\n",
    "\n",
    "XGBoost, short for \"Extreme Gradient Boosting,\" is a popular machine learning algorithm known for its exceptional performance in both classification and regression tasks. It belongs to the gradient boosting family of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a312d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_cs, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_valid_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ede5a837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Balanced Accuracy  Precision  Recall     F1  Kappa\n",
       "XGBoost              0.921       0.96   0.842  0.897  0.897"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results = ml_scores('XGBoost', y_valid, y_pred)\n",
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d6b9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1016706\n",
      "           1       0.96      0.84      0.90      1314\n",
      "\n",
      "    accuracy                           1.00   1018020\n",
      "   macro avg       0.98      0.92      0.95   1018020\n",
      "weighted avg       1.00      1.00      1.00   1018020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9520a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold K=1\n",
      "Fold K=2\n",
      "Fold K=3\n",
      "Fold K=4\n",
      "Fold K=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.918 +/- 0.003</td>\n",
       "      <td>0.9480000000000001 +/- 0.004</td>\n",
       "      <td>0.837 +/- 0.006</td>\n",
       "      <td>0.889 +/- 0.003</td>\n",
       "      <td>0.889 +/- 0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Balanced Accuracy                     Precision           Recall  \\\n",
       "XGBoost   0.918 +/- 0.003  0.9480000000000001 +/- 0.004  0.837 +/- 0.006   \n",
       "\n",
       "                      F1            Kappa  \n",
       "XGBoost  0.889 +/- 0.003  0.889 +/- 0.003  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation\n",
    "xgb_cv = ml_cv_results('XGBoost', XGBClassifier(),\n",
    "                       X_temp_cs, y_temp)\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d9ef9",
   "metadata": {},
   "source": [
    "## Hyperparameter Fine Tuning\n",
    "This code snippet demonstrates hyperparameter fine-tuning using GridSearchCV for an XGBoost classifier (XGBClassifier). It searches through various hyperparameter combinations, including booster type, learning rate (eta), and class weight scaling, optimizing for F1 score as the evaluation metric. The process employs a 3-fold stratified cross-validation scheme to find the best combination of hyperparameters for improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd075e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b898589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eta': [0.3, 0.01],\n",
    "    'scale_pos_weight': [1, 508, 99]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df7ce6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV 1/3; 1/12] START booster=gbtree, eta=0.3, scale_pos_weight=1................\n",
      "[CV 1/3; 1/12] END booster=gbtree, eta=0.3, scale_pos_weight=1;, score=0.892 total time=  13.3s\n",
      "[CV 2/3; 1/12] START booster=gbtree, eta=0.3, scale_pos_weight=1................\n",
      "[CV 2/3; 1/12] END booster=gbtree, eta=0.3, scale_pos_weight=1;, score=0.893 total time=  13.6s\n",
      "[CV 3/3; 1/12] START booster=gbtree, eta=0.3, scale_pos_weight=1................\n",
      "[CV 3/3; 1/12] END booster=gbtree, eta=0.3, scale_pos_weight=1;, score=0.887 total time=  13.5s\n",
      "[CV 1/3; 2/12] START booster=gbtree, eta=0.3, scale_pos_weight=508..............\n",
      "[CV 1/3; 2/12] END booster=gbtree, eta=0.3, scale_pos_weight=508;, score=0.596 total time=  14.4s\n",
      "[CV 2/3; 2/12] START booster=gbtree, eta=0.3, scale_pos_weight=508..............\n",
      "[CV 2/3; 2/12] END booster=gbtree, eta=0.3, scale_pos_weight=508;, score=0.162 total time=  15.8s\n",
      "[CV 3/3; 2/12] START booster=gbtree, eta=0.3, scale_pos_weight=508..............\n",
      "[CV 3/3; 2/12] END booster=gbtree, eta=0.3, scale_pos_weight=508;, score=0.590 total time=  13.9s\n",
      "[CV 1/3; 3/12] START booster=gbtree, eta=0.3, scale_pos_weight=99...............\n",
      "[CV 1/3; 3/12] END booster=gbtree, eta=0.3, scale_pos_weight=99;, score=0.698 total time=  14.7s\n",
      "[CV 2/3; 3/12] START booster=gbtree, eta=0.3, scale_pos_weight=99...............\n",
      "[CV 2/3; 3/12] END booster=gbtree, eta=0.3, scale_pos_weight=99;, score=0.709 total time=  14.2s\n",
      "[CV 3/3; 3/12] START booster=gbtree, eta=0.3, scale_pos_weight=99...............\n",
      "[CV 3/3; 3/12] END booster=gbtree, eta=0.3, scale_pos_weight=99;, score=0.675 total time=  14.2s\n",
      "[CV 1/3; 4/12] START booster=gbtree, eta=0.01, scale_pos_weight=1...............\n",
      "[CV 1/3; 4/12] END booster=gbtree, eta=0.01, scale_pos_weight=1;, score=0.752 total time=  11.1s\n",
      "[CV 2/3; 4/12] START booster=gbtree, eta=0.01, scale_pos_weight=1...............\n",
      "[CV 2/3; 4/12] END booster=gbtree, eta=0.01, scale_pos_weight=1;, score=0.755 total time=  11.1s\n",
      "[CV 3/3; 4/12] START booster=gbtree, eta=0.01, scale_pos_weight=1...............\n",
      "[CV 3/3; 4/12] END booster=gbtree, eta=0.01, scale_pos_weight=1;, score=0.737 total time=  11.0s\n",
      "[CV 1/3; 5/12] START booster=gbtree, eta=0.01, scale_pos_weight=508.............\n",
      "[CV 1/3; 5/12] END booster=gbtree, eta=0.01, scale_pos_weight=508;, score=0.205 total time=  15.6s\n",
      "[CV 2/3; 5/12] START booster=gbtree, eta=0.01, scale_pos_weight=508.............\n",
      "[CV 2/3; 5/12] END booster=gbtree, eta=0.01, scale_pos_weight=508;, score=0.224 total time=  14.2s\n",
      "[CV 3/3; 5/12] START booster=gbtree, eta=0.01, scale_pos_weight=508.............\n",
      "[CV 3/3; 5/12] END booster=gbtree, eta=0.01, scale_pos_weight=508;, score=0.181 total time=  13.8s\n",
      "[CV 1/3; 6/12] START booster=gbtree, eta=0.01, scale_pos_weight=99..............\n",
      "[CV 1/3; 6/12] END booster=gbtree, eta=0.01, scale_pos_weight=99;, score=0.578 total time=  13.7s\n",
      "[CV 2/3; 6/12] START booster=gbtree, eta=0.01, scale_pos_weight=99..............\n",
      "[CV 2/3; 6/12] END booster=gbtree, eta=0.01, scale_pos_weight=99;, score=0.606 total time=  14.1s\n",
      "[CV 3/3; 6/12] START booster=gbtree, eta=0.01, scale_pos_weight=99..............\n",
      "[CV 3/3; 6/12] END booster=gbtree, eta=0.01, scale_pos_weight=99;, score=0.577 total time=  13.7s\n",
      "[CV 1/3; 7/12] START booster=gblinear, eta=0.3, scale_pos_weight=1..............\n",
      "[CV 1/3; 7/12] END booster=gblinear, eta=0.3, scale_pos_weight=1;, score=0.333 total time=  22.8s\n",
      "[CV 2/3; 7/12] START booster=gblinear, eta=0.3, scale_pos_weight=1..............\n",
      "[CV 2/3; 7/12] END booster=gblinear, eta=0.3, scale_pos_weight=1;, score=0.351 total time=  20.8s\n",
      "[CV 3/3; 7/12] START booster=gblinear, eta=0.3, scale_pos_weight=1..............\n",
      "[CV 3/3; 7/12] END booster=gblinear, eta=0.3, scale_pos_weight=1;, score=0.359 total time=  21.5s\n",
      "[CV 1/3; 8/12] START booster=gblinear, eta=0.3, scale_pos_weight=508............\n",
      "[CV 1/3; 8/12] END booster=gblinear, eta=0.3, scale_pos_weight=508;, score=0.041 total time=  21.4s\n",
      "[CV 2/3; 8/12] START booster=gblinear, eta=0.3, scale_pos_weight=508............\n",
      "[CV 2/3; 8/12] END booster=gblinear, eta=0.3, scale_pos_weight=508;, score=0.042 total time=  22.4s\n",
      "[CV 3/3; 8/12] START booster=gblinear, eta=0.3, scale_pos_weight=508............\n",
      "[CV 3/3; 8/12] END booster=gblinear, eta=0.3, scale_pos_weight=508;, score=0.035 total time=  22.8s\n",
      "[CV 1/3; 9/12] START booster=gblinear, eta=0.3, scale_pos_weight=99.............\n",
      "[CV 1/3; 9/12] END booster=gblinear, eta=0.3, scale_pos_weight=99;, score=0.282 total time=  19.5s\n",
      "[CV 2/3; 9/12] START booster=gblinear, eta=0.3, scale_pos_weight=99.............\n",
      "[CV 2/3; 9/12] END booster=gblinear, eta=0.3, scale_pos_weight=99;, score=0.270 total time=  20.9s\n",
      "[CV 3/3; 9/12] START booster=gblinear, eta=0.3, scale_pos_weight=99.............\n",
      "[CV 3/3; 9/12] END booster=gblinear, eta=0.3, scale_pos_weight=99;, score=0.262 total time=  21.6s\n",
      "[CV 1/3; 10/12] START booster=gblinear, eta=0.01, scale_pos_weight=1............\n",
      "[CV 1/3; 10/12] END booster=gblinear, eta=0.01, scale_pos_weight=1;, score=0.000 total time=  22.2s\n",
      "[CV 2/3; 10/12] START booster=gblinear, eta=0.01, scale_pos_weight=1............\n",
      "[CV 2/3; 10/12] END booster=gblinear, eta=0.01, scale_pos_weight=1;, score=0.000 total time=  20.2s\n",
      "[CV 3/3; 10/12] START booster=gblinear, eta=0.01, scale_pos_weight=1............\n",
      "[CV 3/3; 10/12] END booster=gblinear, eta=0.01, scale_pos_weight=1;, score=0.000 total time=  21.6s\n",
      "[CV 1/3; 11/12] START booster=gblinear, eta=0.01, scale_pos_weight=508..........\n",
      "[CV 1/3; 11/12] END booster=gblinear, eta=0.01, scale_pos_weight=508;, score=0.016 total time=  20.5s\n",
      "[CV 2/3; 11/12] START booster=gblinear, eta=0.01, scale_pos_weight=508..........\n",
      "[CV 2/3; 11/12] END booster=gblinear, eta=0.01, scale_pos_weight=508;, score=0.016 total time=  21.7s\n",
      "[CV 3/3; 11/12] START booster=gblinear, eta=0.01, scale_pos_weight=508..........\n",
      "[CV 3/3; 11/12] END booster=gblinear, eta=0.01, scale_pos_weight=508;, score=0.016 total time=  19.4s\n",
      "[CV 1/3; 12/12] START booster=gblinear, eta=0.01, scale_pos_weight=99...........\n",
      "[CV 1/3; 12/12] END booster=gblinear, eta=0.01, scale_pos_weight=99;, score=0.017 total time=  20.9s\n",
      "[CV 2/3; 12/12] START booster=gblinear, eta=0.01, scale_pos_weight=99...........\n",
      "[CV 2/3; 12/12] END booster=gblinear, eta=0.01, scale_pos_weight=99;, score=0.024 total time=  22.0s\n",
      "[CV 3/3; 12/12] START booster=gblinear, eta=0.01, scale_pos_weight=99...........\n",
      "[CV 3/3; 12/12] END booster=gblinear, eta=0.01, scale_pos_weight=99;, score=0.014 total time=  22.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;], &#x27;eta&#x27;: [0.3, 0.01],\n",
       "                         &#x27;scale_pos_weight&#x27;: [1, 508, 99]},\n",
       "             scoring=make_scorer(f1_score), verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;], &#x27;eta&#x27;: [0.3, 0.01],\n",
       "                         &#x27;scale_pos_weight&#x27;: [1, 508, 99]},\n",
       "             scoring=make_scorer(f1_score), verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'booster': ['gbtree', 'gblinear'], 'eta': [0.3, 0.01],\n",
       "                         'scale_pos_weight': [1, 508, 99]},\n",
       "             scoring=make_scorer(f1_score), verbose=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(XGBClassifier(), \n",
    "                  param_grid=params, \n",
    "                  scoring=f1, \n",
    "                  cv=StratifiedKFold(n_splits=3),\n",
    "                  verbose = 10)\n",
    "\n",
    "gs.fit(X_params_cs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1449e94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree', 'eta': 0.3, 'scale_pos_weight': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = gs.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a5102d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'booster': 'gbtree', 'eta': 0.3, 'scale_pos_weight': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c8dd104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8902458161596596"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362689a",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea20d60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the final model with the best hyperparameters\n",
    "final_model = XGBClassifier(\n",
    "    booster=best_params['booster'],\n",
    "    eta=best_params['eta'],\n",
    "    scale_pos_weight=best_params['scale_pos_weight']\n",
    ")\n",
    "\n",
    "final_model.fit(X_params_cs, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc4df33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e6e41d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unseen</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Balanced Accuracy  Precision  Recall    F1  Kappa\n",
       "unseen              0.928       0.97   0.857  0.91   0.91"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_scores = ml_scores('unseen', y_test, y_pred)\n",
    "unseen_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d991f",
   "metadata": {},
   "source": [
    "## Deploy Trained Model as SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dffc6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the target variable (is_fraud) and the feature data for the training set.\n",
    "# This creates a DataFrame 'train' with 'is_fraud' as the first column.\n",
    "# Parameters:\n",
    "# - y_train: Series containing the target labels for the training set.\n",
    "# - X_train_cs: DataFrame containing the feature data for the training set.\n",
    "# Returns:\n",
    "# - train: Concatenated DataFrame with 'is_fraud' as the first column.\n",
    "\n",
    "train = pd.concat([pd.Series(y_train, index=X_train_cs.index,\n",
    "                             name='is_fraud', dtype=int), X_train_cs], axis=1)\n",
    "validation = pd.concat([pd.Series(y_valid, index=X_valid_cs.index,\n",
    "                            name='is_fraud', dtype=int), X_valid_cs], axis=1)\n",
    "test = pd.concat([pd.Series(y_test, index=X_test_cs.index,\n",
    "                            name='is_fraud', dtype=int), X_test_cs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c8b9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "train.to_csv('train_final.csv', index=False, header=False)\n",
    "validation.to_csv('validation_final.csv', index=False, header=False)\n",
    "test.to_csv('test_final.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f964d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is stored in : archana-training-data\n"
     ]
    }
   ],
   "source": [
    "# Upload the data into s3 bucket for better access and streaming during training.\n",
    "bucket = \"archana-training-data\"\n",
    "print(\"Training data is stored in : {}\".format(bucket))\n",
    "prefix = \"demo-sagemaker-xgboost-fraud-detection-prediction\"\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "    os.path.join(prefix, 'data/train_final.csv')).upload_file('train_final.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "    os.path.join(prefix, 'data/validation_final.csv')).upload_file('validation_final.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "    os.path.join(prefix, 'data/test_final.csv')).upload_file('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5845d7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-25 03:42:12  112838841 demo-sagemaker-xgboost-fraud-detection-prediction/data/test_final.csv\r\n",
      "2023-11-25 03:42:08  360986870 demo-sagemaker-xgboost-fraud-detection-prediction/data/train_final.csv\r\n",
      "2023-11-25 03:42:11   90262459 demo-sagemaker-xgboost-fraud-detection-prediction/data/validation_final.csv\r\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {bucket}/{prefix}/data --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a996f739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "AWS Region: us-east-2\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "RoleArn: arn:aws:iam::058263730813:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n"
     ]
    }
   ],
   "source": [
    "region = sagemaker.Session().boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "102599fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define the model along with the training parameters\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket, prefix, 'xgboost_model')\n",
    "container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "\n",
    "xgb_model = sagemaker.estimator.Estimator(\n",
    "    image_uri = container,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m4.xlarge',\n",
    "    volume_size = 5,\n",
    "    output_path = s3_output_location,\n",
    "    sagemaker_session = sagemaker.Session(),\n",
    "    rules = [\n",
    "        Rule.sagemaker(rule_configs.create_xgboost_report()),\n",
    "        ProfilerRule.sagemaker(rule_configs.ProfilerReport())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4c5196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the GridSearch set the hyperparamateres for training\n",
    "xgb_model.set_hyperparameters(\n",
    "    max_depth = 5,\n",
    "    eta = 0.3,\n",
    "    gamma = 4,\n",
    "    min_child_weight = 6,\n",
    "    subsample = 0.7,\n",
    "    objective = \"binary:logistic\",\n",
    "    num_round = 1,\n",
    "    verbosity = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60592853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training input\n",
    "train_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}\".format(bucket, prefix, \"data/train_final.csv\"), content_type=\"csv\"\n",
    ")\n",
    "validation_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}\".format(bucket, prefix, \"data/validation_final.csv\"), content_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bc04f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2023-11-25-03-42-14-333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-25 03:42:14 Starting - Starting the training job...\n",
      "2023-11-25 03:42:40 Starting - Preparing the instances for trainingCreateXgboostReport: InProgress\n",
      "ProfilerReport: InProgress\n",
      ".........\n",
      "2023-11-25 03:44:14 Downloading - Downloading input data...\n",
      "2023-11-25 03:44:41 Training - Downloading the training image......\n",
      "2023-11-25 03:45:40 Training - Training image download completed. Training in progress..\u001b[34m[2023-11-25 03:45:38.622 ip-10-0-231-161.us-east-2.compute.internal:6 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:41.401 ip-10-0-231-161.us-east-2.compute.internal:6 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:41.402 ip-10-0-231-161.us-east-2.compute.internal:6 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:41.402 ip-10-0-231-161.us-east-2.compute.internal:6 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:41.403 ip-10-0-231-161.us-east-2.compute.internal:6 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:41.403 ip-10-0-231-161.us-east-2.compute.internal:6 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 4072076 rows and 7 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 1018020 rows\u001b[0m\n",
      "\u001b[34m[03:45:44] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.00069#011validation-error:0.00072\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:44.685 ip-10-0-231-161.us-east-2.compute.internal:6 INFO hook.py:413] Monitoring the collections: predictions, metrics, labels, hyperparameters, feature_importance\u001b[0m\n",
      "\u001b[34m[2023-11-25 03:45:44.687 ip-10-0-231-161.us-east-2.compute.internal:6 INFO hook.py:476] Hook is writing from the hook with pid: 6\u001b[0m\n",
      "\n",
      "2023-11-25 03:46:14 Uploading - Uploading generated training model\n",
      "2023-11-25 03:46:14 Completed - Training job completed\n",
      "Training seconds: 122\n",
      "Billable seconds: 122\n"
     ]
    }
   ],
   "source": [
    "# Begin training using sagemaker instances\n",
    "xgb_model.fit({\"train\": train_input, \"validation\": validation_input}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93e28336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://archana-training-data/demo-sagemaker-xgboost-fraud-detection-prediction/xgboost_model/sagemaker-xgboost-2023-11-25-03-42-14-333/output/model.tar.gz'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the model data and location\n",
    "xgb_model.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec031987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2023-11-25-03-46-27-047\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2023-11-25-03-46-27-047\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2023-11-25-03-46-27-047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# Deploy the trained model as a sagemaker endpoint for invocation\n",
    "xgb_predictor = xgb_model.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.t2.medium',\n",
    "    serializer = CSVSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc94e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Endpoint: sagemaker-xgboost-2023-11-25-03-46-27-047\n"
     ]
    }
   ],
   "source": [
    "print(\"SageMaker Endpoint: {}\".format(xgb_predictor.endpoint_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
